m2g7_v4 is the version with Dagster + Meltano (Dec-06)
 - new project name: olist-orchestration
 - three jobs defined and depends on sequence
 - need to run job one by one.
 - cannot execute last job run_dbt_transform without skipping first two jobs.
 
# Dagster + Meltano: Automated CSV to BigQuery ELT Pipeline

This project demonstrates a robust, automated data pipeline that extracts data from multiple CSV files, and loads it into Google BigQuery. The entire workflow is orchestrated by [Dagster](https://dagster.io/) and leverages [Meltano](https://meltano.com/) for the core ELT (Extract, Load, Transform) process.

## Overview

The pipeline is designed to be dynamic and scalable. It automatically discovers CSV files in a designated directory, generates a manifest, and uses Meltano to load the data into corresponding tables in BigQuery. The entire process is defined as a Dagster Job and can be scheduled to run periodically based on CRON expression.

### Technology Stack

*   **Orchestrator**: [Dagster](https://dagster.io/)
*   **ELT Framework**: [Meltano](https://meltano.com/)
*   **Extractor (Tap)**: `tap-csv`
*   **Loader (Target)**: `target-bigquery`
*   **Data Warehouse**: [Google BigQuery](https://cloud.google.com/bigquery)
*   **Environment Management**: [Conda](https://docs.conda.io/en/latest/)

## Project Structure

.
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ olist_customers_dataset.csv
‚îÇ ‚îî‚îÄ‚îÄ ... (other olist csv files)
‚îú‚îÄ‚îÄ meltano_orchestration/
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îî‚îÄ‚îÄ definitions.py # Core Dagster definitions (Ops, Jobs, Schedules)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ meltano.yml # Meltano project configuration
‚îú‚îÄ‚îÄ pyproject.toml # Python project definition for Dagster
‚îî‚îÄ‚îÄ README.md # This file


*   `data/`: Directory where all source CSV files should be placed.
*   `meltano_orchestration/definitions.py`: The heart of the Dagster application. It defines the Ops that make up the pipeline, the Job that connects them, and the Schedule that runs the Job.
*   `meltano.yml`: Configures the Meltano plugins (`tap-csv`, `target-bigquery`) and their settings.
*   `pyproject.toml`: Defines the Python project structure and dependencies for Dagster.

## Setup and Installation

Follow these steps to set up and run the project locally.

### 1. Prerequisites

*   [Conda](https://docs.conda.io/en/latest/miniconda.html) installed.
*   Access to a Google Cloud Platform (GCP) project with BigQuery enabled.
*   A GCP Service Account with **BigQuery Data Editor** and **BigQuery Job User** permissions. Download its JSON key file.

### 2. Clone the Repository

```bash
# Clone your project repository
git clone <your-repo-url>
cd meltano-orchestration

--> below sections to be reviewed.
3. Create and Activate Conda Environment
This creates a self-contained environment with all the necessary Python dependencies.

# Create a new conda environment
conda create --name dagster python=3.11 -y

# Activate the environment
conda activate dagster

4. Install Python Dependencies
This command installs Dagster and its development dependencies, as defined in pyproject.toml.

pip install -e ".[dev]"

Next, install the Meltano-specific packages.

pip install dagster-meltano meltano

5. Configure Meltano
First, tell Meltano to install the plugins defined in meltano.yml.

meltano install

Next, configure your meltano.yml file. You need to provide the details for your BigQuery target.

meltano.yml:

plugins:
  extractors:
  - name: tap-csv
    variant: meltanolabs
    pip_url: git+https://github.com/MeltanoLabs/tap-csv.git
    config:
      # The tap will get its file list from this JSON file,
      # which is dynamically generated by a Dagster op.
      files: $MELTANO_PROJECT_ROOT/olist_files_definition.json
  loaders:
  - name: target-bigquery
    variant: adswerve
    pip_url: git+https://github.com/adswerve/target-bigquery.git
    config:
      # --- UPDATE THESE VALUES ---
      project_id: "your-gcp-project-id"
      dataset_id: "your_bigquery_dataset_id"
      credentials_path: "/path/to/your/gcp-service-account.json"
      # Use STREAMING to avoid resource limit issues (file handles, connection pools)
      load_method: STREAMING
      parallelism: 1

6. System Requirement: File Descriptors
Modern data tools can open many files simultaneously. To prevent OSError: [Errno 24] Too many open files, you must increase the file descriptor limit in the shell session where you run Dagster.

# Check your current limit
ulimit -n

# Set a new, higher limit for the current session
ulimit -n 65536

How to Run
1. Start the Dagster UI
From the project root directory (/home/cchen/m2g7_v2/meltano-orchestration/), run the following command chain. This ensures the file limit is raised before starting the server.

ulimit -n 65536 && python -m dagster dev

 Launch a Run Manually
In the Dagster UI, navigate to Overview > Jobs.

Click on the elt_job.

Click the "Launch run" button in the top right to manually trigger the pipeline.

3. Enable the Schedule
In the Dagster UI, navigate to Overview > Schedules.

You will see elt_schedule, which is configured to run daily at midnight.

Click the toggle switch to turn the schedule on.

üìñ Workflow Explained
The entire pipeline is defined in definitions.py as a Dagster Job named elt_job. It consists of two main steps (Ops):

build_json_manifest_op:

This Op scans the ./data/ directory for all *.csv files.

It generates a JSON file (olist_files_definition.json) that acts as a manifest, listing each found CSV file, its target table name, and its primary keys.

This makes the pipeline dynamic‚Äîsimply add or remove CSV files from the data directory, and the pipeline will adapt on the next run.

run_meltano_op:

This Op waits for the manifest to be created.

It then uses the Dagster MeltanoResource to execute the shell command: meltano run tap-csv target-bigquery --force.

Meltano reads the configuration from meltano.yml, finds the path to the JSON manifest, and proceeds to extract and load the data.

üîç Troubleshooting
Throughout the development of this pipeline, several key issues were resolved. If you encounter errors, check these first.

MeltanoCommandError: ... exit code 1: This is a generic error from Dagster indicating that the Meltano process failed. To see the real error, you must run the command manually in your terminal:

bash
# Activate conda env and cd into the inner project directory
conda activate dagster
cd meltano_orchestration/
meltano run tap-csv target-bigquery --force
The output of this command will give you the specific Meltano error.

OSError: [Errno 24] Too many open files: Your operating system's file descriptor limit is too low. Run ulimit -n 65536 in your terminal before starting dagster dev.

Connection pool is full: target-bigquery is making too many concurrent requests. The most robust solution is to set the load_method to STREAMING in your meltano.yml configuration for target-bigquery.

Dagster UI is empty or shows "Code Location Error":

Ensure you are launching dagster dev from the project's root directory (the one containing pyproject.toml).

Use the command python -m dagster dev, which is more reliable than just dagster dev.

Check the "Code locations" page in the Dagster UI for specific error messages.
